# ğŸ¤– AI Resume Screener

An end-to-end **AI-powered Resume Screening System** that evaluates a
candidate's resume against a given job description using a **Large
Language Model (LLM)**.

------------------------------------------------------------------------

## ğŸ“Œ Project Overview

This project automates resume screening by analyzing resumes against job
descriptions and providing structured hiring insights similar to an ATS.

------------------------------------------------------------------------

## ğŸ§  Features

-   Upload PDF resume
-   Paste job description
-   AI-based resume evaluation
-   Match score (0--100)
-   Interview / Reject recommendation
-   Strengths and missing skills

------------------------------------------------------------------------

## ğŸ› ï¸ Tech Stack

-   Frontend: HTML, CSS, JavaScript
-   Backend: Python, Flask
-   AI / LLM
    - Ollama (Dockerized)
    - LLaMA 3.2 (pulled at runtime)
    - Prompt Engineering
-   PDF Parsing: PyMuPDF

------------------------------------------------------------------------

## ğŸ“‚ Project Structure

ai-resume-screener/ â”œâ”€â”€ backend/ â”‚ â”œâ”€â”€ app.py â”‚ â”œâ”€â”€ requirements.txt â”œâ”€â”€
frontend/ â”‚ â””â”€â”€ index.html â””â”€â”€ README.md

------------------------------------------------------------------------

## ğŸ³ Run Using Docker (Recommended)

### Prerequisites
- Docker
- Docker Compose

---

### Step 1: Clone Repository
```bash
git clone https://github.com/your-username/ai-resume-screener.git
cd ai-resume-screener
```

### Step 2: Start Services
```bash
docker-compose up --build
```

This will:
    - Start Ollama container
    - Pull LLaMA 3.2 model
    - Start Flask backend

### Step 3: Pull Model (First Time Only)
```bash
docker exec -it ollama ollama pull llama3.2:3b
```

### Step 4: Access Application
    
    - Backend: http://localhost:5000
    - Health check: http://localhost:5000/health
    - Frontend: open frontend/index.html

---

------------------------------------------------------------------------

## ğŸ“¦ What is NOT Included in the Repository

- Ollama model files (pulled at runtime)
- Docker images
- Virtual environments
- Environment secrets

This keeps the repository lightweight and secure.

------------------------------------------------------------------------

## ğŸš€ Setup

1.  Clone repo
2.  Install backend dependencies
3.  Run Ollama
4.  Start Flask server
5.  Open frontend

------------------------------------------------------------------------

## ğŸ‘¤ Author

Yogiraj Bhilare\
M.Sc. Computer Science

------------------------------------------------------------------------

## ğŸ“œ License

Educational use only.
